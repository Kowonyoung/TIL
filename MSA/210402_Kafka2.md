**Kafka & rabbitMQ 찾아보기**

# Kafka Connect

> Source System: 원본 <br>
> Kafka Connect Source: 원본에서 데이터 가져올 때  <br>
> Kafka Cluster: 토픽에 메세지 데이터 쌓여 있음  <br>
> Kafka Connect Sink : 토픽에서 타겟에 데이터 전달할 때 <br>
> Target System : 타겟 (복제본)

![image](https://user-images.githubusercontent.com/77096463/113370032-cc336180-939d-11eb-85f8-8e273f99fe31.png)

<br>

- 주로 Kakfa Client로 Kafka Cluster에 데이터를 저장하지만, Kafka Connect를 통해서도 데이터를 Import/Export 가능하다.

- 코드 없이 Configuration으로 데이터를 이동시키는 것이 목적
  - Standalone mode, Distribution mode 지원
  - **RESTful API 통해 지원**
  - Stream 혹은 Batch 형태로 데이터 전송 가능
  - 커스텀 Connector를 통한 다양한 Plugin 제공 (S3, File, Hive, Mysql, etc..) 

<br>

### 1. MariaDB 설정

https://mvnrepository.com/artifact/org.mariadb.jdbc/mariadb-java-client/2.7.2 사이트에서 MariaDB Java Client 2.7.2 버전 다운받기

![image](https://user-images.githubusercontent.com/77096463/113371415-3d284880-93a1-11eb-8f96-6e3cad3ea86a.png)

<br>

HeidiSQL로 localhost에 접속한 뒤 mydb 데이터베이스에 users 테이블 생성

```sql
create database mydb;

use mydb;
create table users(
	id int auto_increment primary key,
	user_id varchar(20) not null,
	pwd varchar(20) not null,
	created_at datetime default now()
);
```

생성된 테이블 확인

![image](https://user-images.githubusercontent.com/77096463/113372056-be340f80-93a2-11eb-8063-6413135fbf9f.png)

<br>

:rotating_light:**​ Troubleshooting - Authentication plugin 'caching_sha2_password' cannot be loaded**

- [your_password] 항목에 설정하고 싶은 패스워드를 입력하여 재설정한다.

```
C:\Users\Lenovo>cd "C:\Program Files\MySQL\MySQL Server 8.0\bin"

C:\Program Files\MySQL\MySQL Server 8.0\bin>mysql -u root -p
Enter password: *****

mysql> ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '[your_password]';
Query OK, 0 rows affected (0.07 sec)

mysql> exit
Bye
```

<br>

### 2. Kafka Connect 설치

Kafka Connect 설치

```
C:\cloud>mkdir kafka_connect
C:\cloud>cd kafka_connect

C:\cloud\kafka_connect>curl -O http://packages.confluent.io/archive/6.1/confluent-community-6.1.0.tar.gz
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  326M  100  326M    0     0  11.2M      0  0:00:29  0:00:29 --:--:-- 9148k
```

<br>

Kafka Connect 압축 해제

```
C:\cloud\kafka_connect>tar xvf confluent-community-6.1.0.tar.gz
```

<br>

Kafka Connect 실행 > <u>오류 발생</u>

```
C:\cloud\kafka_connect\confluent-6.1.0>.\bin\windows\connect-distributed.bat .\etc\kafka\connect-distributed.properties
Classpath is empty. Please build the project first e.g. by running 'gradlew jarAll'
```

<br>

:rotating_light: **Troubleshooting : Classpath is empty. Please build the project first e.g. by running 'gradlew jarAll'**

.\bin\windows\kafka-run-class.bat 파일에서 `rem Classpath addition for core` 위에 아래의 코드 추가

```bat
rem classpath for LSB style path
if exist %BASE_DIR%\share\java\kafka\* (
	call:concat %BASE_DIR%\share\java\kafka\*
)
```

<br>

이후 Kafka Connect 재실행하면 정상 작동된다!<br>

````
C:\cloud\kafka_connect\confluent-6.1.0>.\bin\windows\connect-distributed.bat .\etc\kafka\connect-distributed.properties
````

<br>

:warning: 혹시 작동 상에는 문제 없지만 출력되는 로그에 `log4j:ERROR Could not read configuration file from URL [file:C:/cloud/kafka_connect/confluent-6.1.0/config/tools-log4j.properties]. java.io.FileNotFoundException: C:\cloud\kafka_connect\confluent-6.1.0\config\tools-log4j.properties` 가 신경쓰인다면 tools-log4j.properties파일이 없어서 나는 오류이므로 해당 파일을 만들어주면된다.

```properties
# tools-log4j.properties
log4j.rootLogger=ERROR
```

<br>

정상 작동 되었는지 확인 >  connect-~로 시작하는 토픽 리스트가 생성되어야 함

```
[C:\cloud\kafka_2.13-2.7.0]$ bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092
__consumer_offsets
connect-configs
connect-offsets
connect-status
```

<br>

혹은 curl 명령어를 통해 접속 확인 (POSTMAN으로도 확인 가능)

```
[C:\cloud\kafka_2.13-2.7.0]$ curl http://localhost:8083/connectors
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100     2  100     2    0     0      2      0  0:00:01 --:--:--  0:00:01    14
[]

```

<br>

### 3. JDBC Connector 설정

>  Kafka가 scalar 기반이기 때문에 다른 리소스에 있는 데이터를 읽어들이기 위해 여기서는 JDBC 필요

C:\cloud\kafka_connect\confluent-6.1.0\share\java\kafka 경로에 다운받은 mariadb-java-client-2.7.2.jar 파일 복사

![image](https://user-images.githubusercontent.com/77096463/113380957-a5ceef80-93b8-11eb-86e1-91185b44f09f.png)

<br>

https://docs.confluent.io/5.5.1/connect/kafka-connect-jdbc/index.html 사이트에서 confluentinc-kafka-connect-jdbc-10.1.0 다운받고 압축 해제하기

![image](https://user-images.githubusercontent.com/77096463/113381166-3dccd900-93b9-11eb-939a-9dfd70b8e2e2.png)

<br>

etc\kafka\connect-distributed.properties 파일 마지막에 plugin 정보 추가

```properties
plugin.path=\C:\\cloud\\confluentinc-kafka-connect-jdbc-10.1.0\\lib
```

<br>

### 4. Kafka Source Connect 테스트

Kafka Source Connect 추가 (**POST**)

- 포스트맨에서 URL : http://localhost:8083/connectors  설정
- KEY : Content-Type / VALUE: application/json 설정
- BODY > raw 영역 & json 선택

```json
{
"name" : "my source connect",
"config" : {
    "connector.class" : "io.confluent.connect.jdbc.JdbcSourceConnector",
    "connection.url" : "jdbc:mysql://localhost:3306/mydb",
    "connection.user":"root",
    "connection.password":"mysql",
    "mode": "incrementing",
    "incrementing.column.name" : "id",
    "table.whitelist":"users",
    "topic.prefix" : "my_topic_",
    "tasks.max" : "1"
    }
}
```

<br>

Kafka Source Connect 확인 (**GET**)

![image](https://user-images.githubusercontent.com/77096463/113382221-f5fb8100-93bb-11eb-95e4-7cab9c7962de.png)

<br>

Topic list 확인

```
[C:\cloud\kafka_2.13-2.7.0]$ bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092
__consumer_offsets
connect-configs
connect-offsets
connect-status
```

<br>

MariaDB에 데이터를 추가

```sql
INSERT INTO mydb.users(user_id, pwd) VALUES('test2','admin');
```

![image](https://user-images.githubusercontent.com/77096463/113382729-37406080-93bd-11eb-89f4-fac2cfe6f742.png)

<br>

Topic list 재확인

```
[C:\cloud\kafka_2.13-2.7.0]$ bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092
__consumer_offsets
connect-configs
connect-offsets
connect-status
my_topic_users
```

<br>

my_topic_users 토픽에 추가한 내용 들어와있는지 확인

```
[C:\cloud\kafka_2.13-2.7.0]$ bin\windows\kafka-console-consumer.bat --topic my_topic_users --from-beginning --bootstrap-server localhost:9092

{"schema":{"type":"struct","fields":[{"type":"int32","optional":false,"field":"id"},{"type":"string","optional":false,"field":"user_id"},{"type":"string","optional":false,"field":"pwd"},{"type":"int64","optional":true,"name":"org.apache.kafka.connect.data.Timestamp","version":1,"field":"created_at"}],"optional":false,"name":"users"},"payload":{"id":1,"user_id":"test2","pwd":"admin","created_at":1617372371000}}
```

<br>

GET 메서드로 http://localhost:8083/connectors/my-source-connect/status (상세 정보 확인)

![image](https://user-images.githubusercontent.com/77096463/113387946-424cbe00-93c8-11eb-8229-00e82456ca7d.png)

<br>

### 4-1. Kafka Connect 삭제

HTTP DELETE method로 http://localhost:8083/connectors/[생성한 source connect의 이름]

<br>

### 5. Kafka Sink Connect 테스트

Kafka Sink Connect 추가 (POST)

- URL : http://localhost:8083/connectors
- KEY, VALUE는 앞과 동일
- 정상적으로 생성되면 201 상태 
- topics는 my-source-connect의 prefix를 mysql_topic_users로 변경했음

```json
{
"name" : "my-sink-connect",
"config" : {
    "connector.class" : "io.confluent.connect.jdbc.JdbcSinkConnector",
    "connection.url" : "jdbc:mysql://localhost:3306/mydb",
    "connection.user":"root",
    "connection.password":"mysql",
    "auto.create":"true",
    "auto.evolve" : "true",
    "delete.enabled" : "false",
    "tasks.max" : "1",
    "topics" : "mysql_topic_users"
    }
}
```

<br>

GET 메서드로 http://localhost:8083/connectors 

```
[
    "my-sink-connect",
    "my-source-connect"
]
```

<br>

GET 메서드로 http://localhost:8083/connectors/my-sink-connect/status

```
{
    "name": "my-sink-connect",
    "connector": {
        "state": "RUNNING",
        "worker_id": "192.168.56.1:8083"
    },
    "tasks": [
        {
            "id": 0,
            "state": "RUNNING",
            "worker_id": "192.168.56.1:8083"
        }
    ],
    "type": "sink"
}
```

<br>

my-sink-connect에서 설정한 토픽의 이름과 동일한 테이블이 생성되었음을 확인

- users 테이블 -> 토픽 -> mysql_topic_users

![image](https://user-images.githubusercontent.com/77096463/113390357-80e47780-93cc-11eb-8dfd-b9ca8d2ed5a3.png)

<br>

---

### Python (python_producer.py) 이용한 실습

<목표>

- python 코드로 topic에 직접 데이터 전송 (send)
- mysql_topic_users 테이블에서 topic에 전송된 데이터 확인

<br>

python_producer.py 파일 수정

```python
from kafka import KafkaProducer
from json import dumps
import time

# dict (key,value) -> object
# str -> json

# acks 수치가 낮을 수록 체크하지 않겠다는 뜻 -> 성능 올라감
producer = KafkaProducer(acks=0, 
                compression_type='gzip',
                bootstrap_servers=['127.0.0.1:9092'],
                value_serializer=lambda x: dumps(x).encode('utf-8')
                )

start = time.time()

# 10개의 data값 전달
for i in range(1):
    #data = {'name': 'Haerim-' + str(i)}
    #data = {"schema":{"type":"struct","fields":[{"type":"int32","field":"id"},{"type":"string","field":"user_id"},{"type":"string","field":"pwd"},{"type":"string","field":"NAME"},{"type":"int64","name":"org.apache.kafka.connect.data.Timestamp","version":1,"field":"created_at"}],"name":"users"},"payload":{"id":10,"user_id":"new_test10","pwd":"new_pwd10","NAME":"NEW TEST USER10","created_at":1615349727000}}
    data = {"schema":{"type":"struct","fields":[{"type":"int32","field":"id"},{"type":"string","field":"user_id"},{"type":"string","field":"pwd"},{"type":"int64","name":"org.apache.kafka.connect.data.Timestamp","version":1,"field":"created_at"}],"name":"users"},"payload":{"id":4,"user_id":"python_test","pwd":"python","created_at":1617374390000}}

    producer.send('mysql_topic_users', value=data)
    producer.flush()

print("Done. Elapsed time: ", (time.time()-start))
```

<br>

kafka_producer.py 파일 실행 후  mysql_topic_users 토픽에 데이터 들어왔는지 확인

```
[C:\cloud\kafka_2.13-2.7.0]$ bin\windows\kafka-console-consumer.bat --topic mysql_topic_users --from-beginning --bootstrap-server localhost:9092
{"schema":{"type":"struct","fields":[{"type":"int32","optional":false,"field":"id"},{"type":"string","optional":false,"field":"user_id"},{"type":"string","optional":false,"field":"pwd"},{"type":"int64","optional":true,"name":"org.apache.kafka.connect.data.Timestamp","version":1,"field":"created_at"}],"optional":false,"name":"users"},"payload":{"id":1,"user_id":"test2","pwd":"admin","created_at":1617372371000}}

{"schema":{"type":"struct","fields":[{"type":"int32","optional":false,"field":"id"},{"type":"string","optional":false,"field":"user_id"},{"type":"string","optional":false,"field":"pwd"},{"type":"int64","optional":true,"name":"org.apache.kafka.connect.data.Timestamp","version":1,"field":"created_at"}],"optional":false,"name":"users"},"payload":{"id":5,"user_id":"test4","pwd":"admin444","created_at":1617374168000}}

{"schema":{"type":"struct","fields":[{"type":"int32","optional":false,"field":"id"},{"type":"string","optional":false,"field":"user_id"},{"type":"string","optional":false,"field":"pwd"},{"type":"int64","optional":true,"name":"org.apache.kafka.connect.data.Timestamp","version":1,"field":"created_at"}],"optional":false,"name":"users"},"payload":

{"id":6,"user_id":"test5","pwd":"admin555","created_at":1617374390000}}
{"schema": {"type": "struct", "fields": [{"type": "int32", "field": "id"}, {"type": "string", "field": "user_id"}, {"type": "string", "field": "pwd"}, {"type": "int64", "name": "org.apache.kafka.connect.data.Timestamp", "version": 1, "field": "created_at"}], "name": "users"}, "payload": {"id": 4, "user_id": "python_test", "pwd": "python", "created_at": 1617374390000}}
```

<br>

mysql_topic_users 테이블에도 동일한 데이터 들어왔는지 확인

![image](https://user-images.githubusercontent.com/77096463/113394210-c99f2f00-93d2-11eb-874f-e28a8d1d988a.png)

<br>

